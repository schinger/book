<!DOCTYPE html>
<html class="theme theme-white">
<head>
<meta charset="utf-8">
<title>图像分类</title>
<link href="https://www.zybuluo.com/static/assets/template-theme-white.css" rel="stylesheet" media="screen">
<style type="text/css">

#wmd-preview h1  {
    color: #0077bb; /* 将标题改为蓝色 */
}</style>
</head>
<body class="theme theme-white">
<div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_SVG_Hidden"></div><svg><defs id="MathJax_SVG_glyphs"><path id="MJMATHI-61" stroke-width="1" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJMATHI-62" stroke-width="1" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path><path id="MJMATHI-6E" stroke-width="1" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJMATHI-6C" stroke-width="1" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path id="MJMATHI-72" stroke-width="1" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMAIN-30" stroke-width="1" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJMAIN-3D" stroke-width="1" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJMAIN-2217" stroke-width="1" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path><path id="MJMAIN-230A" stroke-width="1" d="M174 734Q174 735 175 737T177 740T180 744T184 747T189 749T196 750Q206 748 214 735V-210H310H373Q401 -210 411 -213T422 -230T411 -247T369 -251Q362 -251 338 -251T298 -250H190Q178 -246 174 -234V734Z"></path><path id="MJMAIN-230B" stroke-width="1" d="M229 734Q229 735 230 737T232 740T235 744T239 747T244 749T251 750Q262 748 269 735V-235Q266 -240 256 -249L147 -250H77Q43 -250 32 -247T21 -230T32 -213T72 -209Q79 -209 99 -209T133 -210H229V734Z"></path><path id="MJMAIN-28" stroke-width="1" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJMATHI-64" stroke-width="1" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path id="MJMATHI-65" stroke-width="1" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJMATHI-70" stroke-width="1" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path id="MJMATHI-74" stroke-width="1" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path id="MJMATHI-68" stroke-width="1" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path id="MJMAIN-2212" stroke-width="1" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJMAIN-32" stroke-width="1" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJMAIN-29" stroke-width="1" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJMATHI-63" stroke-width="1" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJMATHI-66" stroke-width="1" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path id="MJMATHI-67" stroke-width="1" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path id="MJMAIN-20" stroke-width="1"></path><path id="MJMATHI-75" stroke-width="1" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMATHI-73" stroke-width="1" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJMATHI-69" stroke-width="1" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJMATHI-6F" stroke-width="1" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJMAIN-31" stroke-width="1" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJMATHI-6D" stroke-width="1" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMAIN-33" stroke-width="1" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path id="MJMATHI-76" stroke-width="1" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></defs></svg></div><div id="wmd-preview" class="wmd-preview wmd-preview-full-reader"><div class="md-section-divider"></div><div class="md-section-divider"></div><h1 data-anchor-id="hrbw" id="图像分类">图像分类</h1><div class="md-section-divider"></div><h2 data-anchor-id="u1iv" id="背景介绍">背景介绍</h2><p data-anchor-id="u5pj">图像相比文字能够提供更加生动、容易理解及更具艺术感的信息，是人们转递与交换信息的重要来源。在本教程中，我们专注于图像识别领域的一个重要问题，即图像分类。</p><p data-anchor-id="5qbf">图像分类是根据图像的语义信息将不同类别图像区分开来，是计算机视觉中重要的基本问题，也是图像检测、图像分割、物体跟踪、行为分析等其他高层视觉任务的基础。图像分类在很多领域有广泛应用，包括安防领域的人脸识别和智能视频分析等，交通领域的交通场景识别，互联网领域基于内容的图像检索和相册自动归类，医学领域的图像识别等。</p><p data-anchor-id="u2y1">一般来说，图像分类通过手工特征或特征学习方法对整个图像进行全部描述，然后使用分类器判别物体类别，因此如何提取图像的特征至关重要。在深度学习算法之前使用较多的是基于词袋(Bag of Words)模型的物体分类方法。词袋方法从自然语言处理中引入，即一句话可以用一个装了词的袋子表示其特征，袋子中的词为句子中的单词、短语或字。对于图像而言，词袋方法需要构建字典。最简单的词袋模型框架可以设计为<strong>底层特征抽取</strong>、<strong>特征编码</strong>、<strong>分类器设计</strong>三个过程。</p><p data-anchor-id="qj3h">而基于深度学习的图像分类方法，可以通过有监督或无监督的方式<strong>学习</strong>层次化的特征描述，从而取代了手工设计或选择图像特征的工作。深度学习模型中的卷积神经网络(Convolution Neural Network, CNN)近年来在图像领域取得了惊人的成绩，CNN直接利用图像像素信息作为输入，最大程度上保留了输入图像的所有信息，通过卷积操作进行特征的提取和高层抽象，模型输出直接是图像识别的结果。这种基于"输入-输出"直接端到端的学习方法取得了非常好的效果，得到了广泛的应用。</p><p data-anchor-id="5q5x">本教程主要介绍图像分类的深度学习模型，以及如何使用PaddlePaddle训练CNN模型。</p><div class="md-section-divider"></div><h2 data-anchor-id="o34s" id="效果展示">效果展示</h2><p data-anchor-id="ko3q">图像分类包括通用图像分类、细粒度图像分类等。图1展示了通用图像分类效果，即模型可以正确识别图像上的主要物体。</p><p align="center" data-anchor-id="8dbj">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/dog_cat.png" width="350"><br>
图1. 通用图像分类展示
</p><p data-anchor-id="303b">图2展示了细粒度图像分类-花卉识别的效果，要求模型可以正确识别花的类别。</p><p align="center" data-anchor-id="rnwr">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/flowers.png" width="400"><br>
图2. 细粒度图像分类展示
</p><p data-anchor-id="r9d4">一个好的模型既要对不同类别识别正确，同时也应该能够对不同视角、光照、背景、变形或部分遮挡的图像正确识别(这里我们统一称作图像扰动)。图3展示了一些图像的扰动，较好的模型会像聪明的人类一样能够正确识别。</p><p align="center" data-anchor-id="ybfp">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/variations.png" width="550"><br>
图3. 扰动图片展示[22]
</p><div class="md-section-divider"></div><h2 data-anchor-id="xx5f" id="模型概览">模型概览</h2><p data-anchor-id="bc81">图像识别领域大量的研究成果都是建立在<a href="http://host.robots.ox.ac.uk/pascal/VOC/" target="_blank">PASCAL VOC</a>、<a href="http://image-net.org/" target="_blank">ImageNet</a>等公开的数据集上，很多图像识别算法通常在这些数据集上进行测试和比较。PASCAL VOC是2005年发起的一个视觉挑战赛，ImageNet是2010年发起的大规模视觉识别竞赛(ILSVRC)的数据集，在本章中我们基于这些竞赛的一些论文介绍图像分类模型。</p><p data-anchor-id="lndh">在2012年之前的传统图像分类方法可以用背景描述中提到的三步完成，但通常完整建立图像识别模型一般包括底层特征学习、特征编码、空间约束、分类器设计、模型融合等几个阶段。 <br>
  1). <strong>底层特征提取</strong>: 通常从图像中按照固定步长、尺度提取大量局部特征描述。常用的局部特征包括SIFT(Scale-Invariant Feature Transform, 尺度不变特征转换) [<a href="#参考文献">1</a>]、HOG(Histogram of Oriented Gradient, 方向梯度直方图) [<a href="#参考文献">2</a>]、LBP(Local Bianray Pattern, 局部二值模式) [<a href="#参考文献">3</a>] 等，一般也采用多种特征描述子，防止丢失过多的有用信息。 <br>
  2). <strong>特征编码</strong>: 底层特征中包含了大量冗余与噪声，为了提高特征表达的鲁棒性，需要使用一种特征变换算法对底层特征进行编码，称作特征编码。常用的特征编码包括向量量化编码 [<a href="#参考文献">4</a>]、稀疏编码 [<a href="#参考文献">5</a>]、局部线性约束编码 [<a href="#参考文献">6</a>]、Fisher向量编码 [<a href="#参考文献">7</a>] 等。 <br>
  3). <strong>空间特征约束</strong>: 特征编码之后一般会经过空间特征约束，也称作<strong>特征汇聚</strong>。特征汇聚是指在一个空间范围内，对每一维特征取最大值或者平均值，可以获得一定特征不变形的特征表达。金字塔特征匹配是一种常用的特征聚会方法，这种方法提出将图像均匀分块，在分块内做特征汇聚。 <br>
  4). <strong>通过分类器分类</strong>: 经过前面步骤之后一张图像可以用一个固定维度的向量进行描述，接下来就是经过分类器对图像进行分类。通常使用的分类器包括SVM(Support Vector Machine, 支持向量机)、随机森林等。而使用核方法的SVM是最为广泛的分类器，在传统图像分类任务上性能很好。</p><p data-anchor-id="iyvz">这种方法在PASCAL VOC竞赛中的图像分类算法中被广泛使用 [<a href="#参考文献">18</a>]。<a href="http://www.nec-labs.com/" target="_blank">NEC实验室</a>在ILSVRC2010中采用SIFT和LBP特征，两个非线性编码器以及SVM分类器获得图像分类的冠军 [<a href="#参考文献">8</a>]。</p><p data-anchor-id="delz">Alex Krizhevsky在2012年ILSVRC提出的CNN模型 [<a href="#参考文献">9</a>] 取得了历史性的突破，效果大幅度超越传统方法，获得了ILSVRC2012冠军，该模型被称作AlexNet。这也是首次将深度学习用于大规模图像分类中。从AlexNet之后，涌现了一系列CNN模型，不断地在ImageNet上刷新成绩，如图4展示。随着模型变得越来越深以及精妙的结构设计，Top-5的错误率也越来越低，降到了3.5%附近。而在同样的ImageNet数据集上，人眼的辨识错误率大概在5.1%，也就是目前的深度学习模型的识别能力已经超过了人眼。</p><p align="center" data-anchor-id="wr6w">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/ilsvrc.png" width="500"><br>
图4. ILSVRC图像分类Top-5错误率
</p><div class="md-section-divider"></div><h3 data-anchor-id="jppq" id="cnn">CNN</h3><p data-anchor-id="4ehp">传统CNN包含卷积层、全连接层等组件，并采用softmax多类别分类器和多类交叉熵损失函数，一个典型的卷积神经网络如图5所示，我们先介绍用来构造CNN的常见组件。</p><p align="center" data-anchor-id="p9hi">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/lenet.png"><br>
图5. CNN网络示例[20] 
</p><ul data-anchor-id="jine">
<li>卷积层(convolution layer): 执行卷积操作提取底层到高层的特征，发掘出图片局部关联性质和空间不变性质。</li>
<li>池化层(pooling layer): 执行降采样操作。通过取卷积输出特征图中局部区块的最大值(max-pooling)或者均值(avg-pooling)。降采样也是图像处理中常见的一种操作，可以过滤掉一些不重要的高频信息。</li>
<li>全连接层(fully-connected layer，或者fc layer): 输入层到隐藏层的神经元是全部连接的。</li>
<li>非线性变化: 卷积层、全连接层后面一般都会接非线性变化层，例如Sigmoid、Tanh、ReLu等来增强网络的表达能力，在CNN里最常使用的为ReLu激活函数。</li>
<li>Dropout [<a href="#参考文献">10</a>] : 在模型训练阶段随机让一些隐层节点权重不工作，提高网络的泛化能力，一定程度上防止过拟合。</li>
</ul><p data-anchor-id="1342">另外，在训练过程中由于每层参数不断更新，会导致下一次输入分布发生变化，这样导致训练过程需要精心设计超参数。如2015年Sergey Ioffe和Christian Szegedy提出了Batch Normalization (BN)算法 [<a href="#参考文献">14</a>] 中，每个batch对网络中的每一层特征都做归一化，使得每层分布相对稳定。BN算法不仅起到一定的正则作用，而且弱化了一些超参数的设计。经过实验证明，BN算法加速了模型收敛过程，在后来较深的模型中被广泛使用。</p><p data-anchor-id="22w8">接下来我们主要介绍VGG，GoogleNet和ResNet网络结构。</p><div class="md-section-divider"></div><h3 data-anchor-id="bpai" id="vgg">VGG</h3><p data-anchor-id="2q5r">牛津大学VGG(Visual Geometry Group)组在2014年ILSVRC提出的模型被称作VGG模型 [<a href="#参考文献">11</a>] 。该模型相比以往模型进一步加宽和加深了网络结构，它的核心是五组卷积操作，每两组之间做Max-Pooling空间降维。同一组内采用多次连续的3X3卷积，卷积核的数目由较浅组的64增多到最深组的512，同一组内的卷积核数目是一样的。卷积之后接两层全连接层，之后是分类层。由于每组内卷积层的不同，有11、13、16、19层这几种模型，下图展示一个16层的网络结构。VGG模型结构相对简洁，提出之后也有很多文章基于此模型进行研究，如在ImageNet上首次公开超过人眼识别的模型[<a href="#参考文献">19</a>]就是借鉴VGG模型的结构。</p><p align="center" data-anchor-id="kc4k">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/vgg16.png" width="750"><br>
图6. 基于ImageNet的VGG16模型
</p><div class="md-section-divider"></div><h3 data-anchor-id="8lel" id="googlenet">GoogleNet</h3><p data-anchor-id="g6uy">GoogleNet [<a href="#参考文献">12</a>] 在2014年ILSVRC的获得了冠军，在介绍该模型之前我们先来了解NIN(Network in Network)模型 [<a href="#参考文献">13</a>] 和Inception模块，因为GoogleNet模型由多组Inception模块组成，模型设计借鉴了NIN的一些思想。</p><p data-anchor-id="r1b0">NIN模型主要有两个特点：1) 引入了多层感知卷积网络(Multi-Layer Perceptron Convolution, MLPconv)代替一层线性卷积网络。MLPconv是一个微小的多层卷积网络，即在线性卷积后面增加若干层1x1的卷积，这样可以提取出高度非线性特征。2) 传统的CNN最后几层一般都是全连接层，参数较多。而NIN模型设计最后一层卷积层包含类别维度大小的特征图，然后采用全局均值池化(Avg-Pooling)替代全连接层，得到类别维度大小的向量，再进行分类。这种替代全连接层的方式有利于减少参数。</p><p data-anchor-id="1r5c">Inception模块如下图7所示，图(a)是最简单的设计，输出是3个卷积层和一个池化层的特征拼接。这种设计的缺点是池化层不会改变特征通道数，拼接后会导致特征的通道数较大，经过几层这样的模块堆积后，通道数会越来越大，导致参数和计算量也随之增大。为了改善这个缺点，图(b)引入3个1x1卷积层进行降维，所谓的降维就是减少通道数，同时如NIN模型中提到的1x1卷积也可以修正线性特征。</p><p align="center" data-anchor-id="g0ha">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/inception.png" width="800"><br>
图7. Inception模块
</p><p data-anchor-id="hdi3">GoogleNet由多组Inception模块堆积而成。另外，在网络最后也没有采用传统的多层全连接层，而是像NIN网络一样采用了均值池化层；但与NIN不同的是，池化层后面接了一层到类别数映射的全连接层。除了这两个特点之外，由于网络中间层特征也很有判别性，GoogleNet在中间层添加了两个辅助分类器，在后向传播中增强梯度并且增强正则化，而整个网络的损失函数是这个三个分类器的损失加权求和。</p><p data-anchor-id="3x7i">GoogleNet整体网络结构如图8所示，总共22层网络：开始由3层普通的卷积组成；接下来由三组子网络组成，第一组子网络包含2个Inception模块，第二组包含5个Inception模块，第三组包含2个Inception模块；然后接均值池化层、全连接层。</p><p align="center" data-anchor-id="krg6">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/googlenet.jpeg"><br>
图8. GoogleNet[12] 
</p><p data-anchor-id="av04">上面介绍的是GoogleNet第一版模型(称作GoogleNet-v1)。GoogleNet-v2 [<a href="#参考文献">14</a>] 引入BN层；GoogleNet-v3 [<a href="#参考文献">16</a>] 对一些卷积层做了分解，进一步提高网络非线性能力和加深网络；GoogleNet-v4 [<a href="#参考文献">17</a>] 引入下面要讲的ResNet设计思路。从v1到v4每一版的改进都会带来准确度的提升，介于篇幅，这里不再详细介绍v2到v4的结构。</p><div class="md-section-divider"></div><h3 data-anchor-id="6qb7" id="resnet">ResNet</h3><p data-anchor-id="fl7g">ResNet(Residual Network) [<a href="#参考文献">15</a>] 是2015年ImageNet图像分类、图像物体定位和图像物体检测比赛的冠军。针对训练卷积神经网络时加深网络导致准确度下降的问题，ResNet提出了采用残差学习。在已有设计思路(BN, 小卷积核，全卷积网络)的基础上，引入了残差模块。每个残差模块包含两条路径，其中一条路径是输入特征的直连通路，另一条路径对该特征做两到三次卷积操作得到该特征的残差，最后再将两条路径上的特征相加。</p><p data-anchor-id="rvdb">残差模块如图9所示，左边是基本模块连接方式，由两个输出通道数相同的3x3卷积组成。右边是瓶颈模块(Bottleneck)连接方式，之所以称为瓶颈，是因为上面的1x1卷积用来降维(图示例即256-&gt;64)，下面的1x1卷积用来升维(图示例即64-&gt;256)，这样中间3x3卷积的输入和输出通道数都较小(图示例即64-&gt;64)。</p><p align="center" data-anchor-id="fec2">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/resnet_block.jpg" width="400"><br>
图9. 残差模块
</p><p data-anchor-id="txqs">图10展示了50、101、152层网络连接示意图，使用的是瓶颈模块。这三个模型的区别在于每组中残差模块的重复次数不同(见图右上角)。ResNet训练收敛较快，成功的训练了上百乃至近千层的卷积神经网络。</p><p align="center" data-anchor-id="mlgg">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/resnet.png"><br>
图10. 基于ImageNet的ResNet模型
</p><div class="md-section-divider"></div><h2 data-anchor-id="pny1" id="数据准备">数据准备</h2><div class="md-section-divider"></div><h3 data-anchor-id="vsax" id="数据介绍与下载">数据介绍与下载</h3><p data-anchor-id="aq4f">通用图像分类公开的标准数据集常用的有<a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">CIFAR</a>、<a href="http://image-net.org/" target="_blank">ImageNet</a>、<a href="http://mscoco.org/" target="_blank">COCO</a>等，常用的细粒度图像分类数据集包括<a href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html" target="_blank">CUB-200-2011</a>、<a href="http://vision.stanford.edu/aditya86/ImageNetDogs/" target="_blank">Stanford Dog</a>、<a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/" target="_blank">Oxford-flowers</a>等。其中ImageNet数据集规模相对较大，如<a href="#模型概览">模型概览</a>一章所讲，大量研究成果基于ImageNet。ImageNet数据从2010年来稍有变化，常用的是ImageNet-2012数据集，该数据集包含1000个类别：训练集包含1,281,167张图片，每个类别数据732至1300张不等，验证集包含50,000张图片，平均每个类别50张图片。</p><p data-anchor-id="28sa">由于ImageNet数据集较大，下载和训练较慢，为了方便大家学习，我们使用<a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">CIFAR10</a>数据集。CIFAR10数据集包含60,000张32x32的彩色图片，10个类别，每个类包含6,000张。其中50,000张图片作为训练集，10000张作为测试集。图11从每个类别中随机抽取了10张图片，展示了所有的类别。</p><p align="center" data-anchor-id="02tp">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/cifar.png" width="350"><br>
图11. CIFAR10数据集[21]
</p><p data-anchor-id="ustq">下面命令用于下载数据和基于训练集计算图像均值，在网络输入前，基于该均值对输入数据做预处理。</p><pre data-anchor-id="wtms"><code>./data/get_data.sh
</code></pre><div class="md-section-divider"></div><h3 data-anchor-id="ioul" id="数据提供给paddlepaddle">数据提供给PaddlePaddle</h3><p data-anchor-id="u280">我们使用Python接口传递数据给系统，下面 <code>dataprovider.py</code> 针对CIFAR10数据给出了完整示例。</p><ul data-anchor-id="ptpg">
<li><p><code>initializer</code> 函数进行dataprovider的初始化，这里加载图像的均值，定义了输入image和label两个字段的类型。</p></li>
<li><p><code>process</code> 函数将数据逐条传输给系统，在图像分类任务里，可以在该函数中完成数据扰动操作，再传输给PaddlePaddle。这里对训练集做随机左右翻转，并将原始图片减去均值后传输给系统。</p>

<pre class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">import</span><span class="pln"> numpy </span><span class="kwd">as</span><span class="pln"> np</span></code></li><li class="L1"><code class="language-python"><span class="kwd">import</span><span class="pln"> cPickle</span></code></li><li class="L2"><code class="language-python"><span class="kwd">from</span><span class="pln"> paddle</span><span class="pun">.</span><span class="pln">trainer</span><span class="pun">.</span><span class="typ">PyDataProvider2</span><span class="pln"> </span><span class="kwd">import</span><span class="pln"> </span><span class="pun">*</span></code></li><li class="L3"><code class="language-python"></code></li><li class="L4"><code class="language-python"><span class="kwd">def</span><span class="pln"> initializer</span><span class="pun">(</span><span class="pln">settings</span><span class="pun">,</span><span class="pln"> mean_path</span><span class="pun">,</span><span class="pln"> is_train</span><span class="pun">,</span><span class="pln"> </span><span class="pun">**</span><span class="pln">kwargs</span><span class="pun">):</span></code></li><li class="L5"><code class="language-python"><span class="pln">  settings</span><span class="pun">.</span><span class="pln">is_train </span><span class="pun">=</span><span class="pln"> is_train</span></code></li><li class="L6"><code class="language-python"><span class="pln">  settings</span><span class="pun">.</span><span class="pln">input_size </span><span class="pun">=</span><span class="pln"> </span><span class="lit">3</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> </span><span class="lit">32</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> </span><span class="lit">32</span></code></li><li class="L7"><code class="language-python"><span class="pln">  settings</span><span class="pun">.</span><span class="pln">mean </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">load</span><span class="pun">(</span><span class="pln">mean_path</span><span class="pun">)[</span><span class="str">'mean'</span><span class="pun">]</span></code></li><li class="L8"><code class="language-python"><span class="pln">  settings</span><span class="pun">.</span><span class="pln">input_types </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{</span></code></li><li class="L9"><code class="language-python"><span class="pln">      </span><span class="str">'image'</span><span class="pun">:</span><span class="pln"> dense_vector</span><span class="pun">(</span><span class="pln">settings</span><span class="pun">.</span><span class="pln">input_size</span><span class="pun">),</span></code></li><li class="L0"><code class="language-python"><span class="pln">      </span><span class="str">'label'</span><span class="pun">:</span><span class="pln"> integer_value</span><span class="pun">(</span><span class="lit">10</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">  </span><span class="pun">}</span></code></li><li class="L2"><code class="language-python"></code></li><li class="L3"><code class="language-python"></code></li><li class="L4"><code class="language-python"><span class="lit">@provider</span><span class="pun">(</span><span class="pln">init_hook</span><span class="pun">=</span><span class="pln">initializer</span><span class="pun">,</span><span class="pln"> cache</span><span class="pun">=</span><span class="typ">CacheType</span><span class="pun">.</span><span class="pln">CACHE_PASS_IN_MEM</span><span class="pun">)</span></code></li><li class="L5"><code class="language-python"><span class="kwd">def</span><span class="pln"> process</span><span class="pun">(</span><span class="pln">settings</span><span class="pun">,</span><span class="pln"> file_list</span><span class="pun">):</span></code></li><li class="L6"><code class="language-python"><span class="pln">  </span><span class="kwd">with</span><span class="pln"> open</span><span class="pun">(</span><span class="pln">file_list</span><span class="pun">,</span><span class="pln"> </span><span class="str">'r'</span><span class="pun">)</span><span class="pln"> </span><span class="kwd">as</span><span class="pln"> fdata</span><span class="pun">:</span></code></li><li class="L7"><code class="language-python"><span class="pln">      </span><span class="kwd">for</span><span class="pln"> fname </span><span class="kwd">in</span><span class="pln"> fdata</span><span class="pun">:</span></code></li><li class="L8"><code class="language-python"><span class="pln">          fo </span><span class="pun">=</span><span class="pln"> open</span><span class="pun">(</span><span class="pln">fname</span><span class="pun">.</span><span class="pln">strip</span><span class="pun">(),</span><span class="pln"> </span><span class="str">'rb'</span><span class="pun">)</span></code></li><li class="L9"><code class="language-python"><span class="pln">          batch </span><span class="pun">=</span><span class="pln"> cPickle</span><span class="pun">.</span><span class="pln">load</span><span class="pun">(</span><span class="pln">fo</span><span class="pun">)</span></code></li><li class="L0"><code class="language-python"><span class="pln">          fo</span><span class="pun">.</span><span class="pln">close</span><span class="pun">()</span></code></li><li class="L1"><code class="language-python"><span class="pln">          images </span><span class="pun">=</span><span class="pln"> batch</span><span class="pun">[</span><span class="str">'data'</span><span class="pun">]</span></code></li><li class="L2"><code class="language-python"><span class="pln">          labels </span><span class="pun">=</span><span class="pln"> batch</span><span class="pun">[</span><span class="str">'labels'</span><span class="pun">]</span></code></li><li class="L3"><code class="language-python"><span class="pln">          </span><span class="kwd">for</span><span class="pln"> im</span><span class="pun">,</span><span class="pln"> lab </span><span class="kwd">in</span><span class="pln"> zip</span><span class="pun">(</span><span class="pln">images</span><span class="pun">,</span><span class="pln"> labels</span><span class="pun">):</span></code></li><li class="L4"><code class="language-python"><span class="pln">              </span><span class="kwd">if</span><span class="pln"> settings</span><span class="pun">.</span><span class="pln">is_train </span><span class="kwd">and</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">random</span><span class="pun">.</span><span class="pln">randint</span><span class="pun">(</span><span class="lit">2</span><span class="pun">):</span></code></li><li class="L5"><code class="language-python"><span class="pln">                  im </span><span class="pun">=</span><span class="pln"> im</span><span class="pun">[:,:,::-</span><span class="lit">1</span><span class="pun">]</span></code></li><li class="L6"><code class="language-python"><span class="pln">              im </span><span class="pun">=</span><span class="pln"> im </span><span class="pun">-</span><span class="pln"> settings</span><span class="pun">.</span><span class="pln">mean</span></code></li><li class="L7"><code class="language-python"><span class="pln">              </span><span class="kwd">yield</span><span class="pln"> </span><span class="pun">{</span></code></li><li class="L8"><code class="language-python"><span class="pln">                  </span><span class="str">'image'</span><span class="pun">:</span><span class="pln"> im</span><span class="pun">.</span><span class="pln">astype</span><span class="pun">(</span><span class="str">'float32'</span><span class="pun">),</span></code></li><li class="L9"><code class="language-python"><span class="pln">                  </span><span class="str">'label'</span><span class="pun">:</span><span class="pln"> int</span><span class="pun">(</span><span class="pln">lab</span><span class="pun">)</span></code></li><li class="L0"><code class="language-python"><span class="pln">              </span><span class="pun">}</span></code></li></ol></pre></li>
</ul><div class="md-section-divider"></div><h2 data-anchor-id="oc08" id="模型配置说明">模型配置说明</h2><div class="md-section-divider"></div><h3 data-anchor-id="45ek" id="数据定义">数据定义</h3><p data-anchor-id="zs50">在模型配置中，定义通过 <code>define_py_data_sources2</code> 函数从 dataprovider 中读入数据， 其中 args 指定均值文件的路径。如果该配置文件用于预测，则不需要数据定义部分。</p><pre data-anchor-id="gg54"><code>from paddle.trainer_config_helpers import *

is_predict = get_config_arg("is_predict", bool, False)
if not is_predict:
    define_py_data_sources2(
        train_list='data/train.list',
        test_list='data/test.list',
        module='dataprovider',
        obj='process',
        args={'mean_path': 'data/mean.meta'})
</code></pre><div class="md-section-divider"></div><h3 data-anchor-id="rwn5" id="算法配置">算法配置</h3><p data-anchor-id="01cy">在模型配置中，通过 <code>settings</code> 设置训练使用的优化算法，并指定batch size 、初始学习率、momentum以及L2正则。</p><pre data-anchor-id="20mk"><code>settings(
    batch_size=128,
    learning_rate=0.1 / 128.0,
    learning_rate_decay_a=0.1,
    learning_rate_decay_b=50000 * 100,
    learning_rate_schedule='discexp',
    learning_method=MomentumOptimizer(0.9),
    regularization=L2Regularization(0.0005 * 128),)
</code></pre><p data-anchor-id="tmhm">通过 <code>learning_rate_decay_a</code> (简写<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -462.0516853480245 529.5 493.10337069604896" style="width: 1.274ex; height: 1.158ex; vertical-align: -0.116ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-61"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1">a</script>） 、<code>learning_rate_decay_b</code> (简写<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -715.0516853480245 429.5 747.103370696049" style="width: 1.042ex; height: 1.737ex; vertical-align: -0.116ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-62"></use></g></svg></span><script type="math/tex" id="MathJax-Element-2">b</script>) 和 <code>learning_rate_schedule</code> 指定学习率调整策略，这里采用离散指数的方式调节学习率，计算公式如下， <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -464.0516853480245 600.5 496.10337069604896" style="width: 1.39ex; height: 1.158ex; vertical-align: -0.116ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-6E"></use></g></svg></span><script type="math/tex" id="MathJax-Element-3">n</script> 代表已经处理过的累计总样本数，<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -716.0516853480245 1203.906943983867 902.3668266633396" style="width: 2.78ex; height: 2.085ex; vertical-align: -0.579ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-6C"></use><g transform="translate(298,0)"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-72"></use><use transform="scale(0.7071067811865476)" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-30" x="638" y="-213"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-4">lr_{0}</script> 即为 <code>settings</code> 里设置的 <code>learning_rate</code>。</p><div class="md-section-divider"></div><p data-anchor-id="6aml"><span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1016.2068841897235 6151.274872458707 1202.5220255050385" style="width: 14.247ex; height: 2.78ex; vertical-align: -0.579ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-6C"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-72" x="298" y="0"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-3D" x="1027" y="0"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-6C" x="2084" y="0"></use><g transform="translate(2382,0)"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-72"></use><use transform="scale(0.7071067811865476)" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-30" x="638" y="-213"></use></g><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-2217" x="3510" y="0"></use><g transform="translate(4232,0)"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-61"></use><g transform="translate(529,437)"><use transform="scale(0.7071067811865476)" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-230A"></use><g transform="translate(434,0)"><rect stroke="none" width="420" height="60" x="0" y="146"></rect><use transform="scale(0.5000000000000001)" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-6E" x="119" y="672"></use><use transform="scale(0.5000000000000001)" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-62" x="205" y="-649"></use></g><use transform="scale(0.7071067811865476)" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-230B" x="1378" y="0"></use></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-5">  lr = lr_{0} * a^ {\lfloor \frac{n}{ b}\rfloor} </script></p><div class="md-section-divider"></div><h3 data-anchor-id="gykl" id="模型结构">模型结构</h3><p data-anchor-id="jvuq">本教程中我们提供了VGG和ResNet两个模型的配置。</p><div class="md-section-divider"></div><h4 data-anchor-id="lptu" id="vgg-1">VGG</h4><p data-anchor-id="bvtv">首先介绍VGG模型结构，由于CIFAR10图片大小和数量相比ImageNet数据小很多，因此这里的模型针对CIFAR10数据做了一定的适配。卷积部分引入了BN和Dropout操作。</p><ol data-anchor-id="elv2">
<li><p>定义数据输入及其维度</p>

<p>网络输入定义为 <code>data_layer</code> (数据层)，在图像分类中即为图像像素信息。CIFRAR10是RGB 3通道32x32大小的彩色图，因此输入数据大小为3072(3x32x32)，类别大小为10，即10分类。</p>

<pre class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"></code></li><li class="L1"><code class="language-python"><span class="pln">datadim </span><span class="pun">=</span><span class="pln"> </span><span class="lit">3</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> </span><span class="lit">32</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> </span><span class="lit">32</span></code></li><li class="L2"><code class="language-python"><span class="pln">classdim </span><span class="pun">=</span><span class="pln"> </span><span class="lit">10</span></code></li><li class="L3"><code class="language-python"><span class="pln">data </span><span class="pun">=</span><span class="pln"> data_layer</span><span class="pun">(</span><span class="pln">name</span><span class="pun">=</span><span class="str">'image'</span><span class="pun">,</span><span class="pln"> size</span><span class="pun">=</span><span class="pln">datadim</span><span class="pun">)</span></code></li></ol></pre></li>
<li><p>定义VGG网络核心模块</p>

<pre class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">net </span><span class="pun">=</span><span class="pln"> vgg_bn_drop</span><span class="pun">(</span><span class="pln">data</span><span class="pun">)</span></code></li></ol></pre>

<p>VGG核心模块的输入是数据层，<code>vgg_bn_drop</code> 定义了16层VGG结构，每层卷积后面引入BN层和Dropout层，详细的定义如下：</p>

<pre class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">def</span><span class="pln"> vgg_bn_drop</span><span class="pun">(</span><span class="pln">input</span><span class="pun">,</span><span class="pln"> num_channels</span><span class="pun">):</span></code></li><li class="L1"><code class="language-python"><span class="pln">    </span><span class="kwd">def</span><span class="pln"> conv_block</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> num_filter</span><span class="pun">,</span><span class="pln"> groups</span><span class="pun">,</span><span class="pln"> dropouts</span><span class="pun">,</span><span class="pln"> num_channels_</span><span class="pun">=</span><span class="kwd">None</span><span class="pun">):</span></code></li><li class="L2"><code class="language-python"><span class="pln">        </span><span class="kwd">return</span><span class="pln"> img_conv_group</span><span class="pun">(</span></code></li><li class="L3"><code class="language-python"><span class="pln">            input</span><span class="pun">=</span><span class="pln">ipt</span><span class="pun">,</span></code></li><li class="L4"><code class="language-python"><span class="pln">            num_channels</span><span class="pun">=</span><span class="pln">num_channels_</span><span class="pun">,</span></code></li><li class="L5"><code class="language-python"><span class="pln">            pool_size</span><span class="pun">=</span><span class="lit">2</span><span class="pun">,</span></code></li><li class="L6"><code class="language-python"><span class="pln">            pool_stride</span><span class="pun">=</span><span class="lit">2</span><span class="pun">,</span></code></li><li class="L7"><code class="language-python"><span class="pln">            conv_num_filter</span><span class="pun">=[</span><span class="pln">num_filter</span><span class="pun">]</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> groups</span><span class="pun">,</span></code></li><li class="L8"><code class="language-python"><span class="pln">            conv_filter_size</span><span class="pun">=</span><span class="lit">3</span><span class="pun">,</span></code></li><li class="L9"><code class="language-python"><span class="pln">            conv_act</span><span class="pun">=</span><span class="typ">ReluActivation</span><span class="pun">(),</span></code></li><li class="L0"><code class="language-python"><span class="pln">            conv_with_batchnorm</span><span class="pun">=</span><span class="kwd">True</span><span class="pun">,</span></code></li><li class="L1"><code class="language-python"><span class="pln">            conv_batchnorm_drop_rate</span><span class="pun">=</span><span class="pln">dropouts</span><span class="pun">,</span></code></li><li class="L2"><code class="language-python"><span class="pln">            pool_type</span><span class="pun">=</span><span class="typ">MaxPooling</span><span class="pun">())</span></code></li><li class="L3"><code class="language-python"></code></li><li class="L4"><code class="language-python"><span class="pln">    conv1 </span><span class="pun">=</span><span class="pln"> conv_block</span><span class="pun">(</span><span class="pln">input</span><span class="pun">,</span><span class="pln"> </span><span class="lit">64</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="pun">[</span><span class="lit">0.3</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">],</span><span class="pln"> </span><span class="lit">3</span><span class="pun">)</span></code></li><li class="L5"><code class="language-python"><span class="pln">    conv2 </span><span class="pun">=</span><span class="pln"> conv_block</span><span class="pun">(</span><span class="pln">conv1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">128</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="pun">[</span><span class="lit">0.4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">])</span></code></li><li class="L6"><code class="language-python"><span class="pln">    conv3 </span><span class="pun">=</span><span class="pln"> conv_block</span><span class="pun">(</span><span class="pln">conv2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">256</span><span class="pun">,</span><span class="pln"> </span><span class="lit">3</span><span class="pun">,</span><span class="pln"> </span><span class="pun">[</span><span class="lit">0.4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0.4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">])</span></code></li><li class="L7"><code class="language-python"><span class="pln">    conv4 </span><span class="pun">=</span><span class="pln"> conv_block</span><span class="pun">(</span><span class="pln">conv3</span><span class="pun">,</span><span class="pln"> </span><span class="lit">512</span><span class="pun">,</span><span class="pln"> </span><span class="lit">3</span><span class="pun">,</span><span class="pln"> </span><span class="pun">[</span><span class="lit">0.4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0.4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">])</span></code></li><li class="L8"><code class="language-python"><span class="pln">    conv5 </span><span class="pun">=</span><span class="pln"> conv_block</span><span class="pun">(</span><span class="pln">conv4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">512</span><span class="pun">,</span><span class="pln"> </span><span class="lit">3</span><span class="pun">,</span><span class="pln"> </span><span class="pun">[</span><span class="lit">0.4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0.4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">])</span></code></li><li class="L9"><code class="language-python"></code></li><li class="L0"><code class="language-python"><span class="pln">    drop </span><span class="pun">=</span><span class="pln"> dropout_layer</span><span class="pun">(</span><span class="pln">input</span><span class="pun">=</span><span class="pln">conv5</span><span class="pun">,</span><span class="pln"> dropout_rate</span><span class="pun">=</span><span class="lit">0.5</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">    fc1 </span><span class="pun">=</span><span class="pln"> fc_layer</span><span class="pun">(</span><span class="pln">input</span><span class="pun">=</span><span class="pln">drop</span><span class="pun">,</span><span class="pln"> size</span><span class="pun">=</span><span class="lit">512</span><span class="pun">,</span><span class="pln"> act</span><span class="pun">=</span><span class="typ">LinearActivation</span><span class="pun">())</span></code></li><li class="L2"><code class="language-python"><span class="pln">    bn </span><span class="pun">=</span><span class="pln"> batch_norm_layer</span><span class="pun">(</span></code></li><li class="L3"><code class="language-python"><span class="pln">        input</span><span class="pun">=</span><span class="pln">fc1</span><span class="pun">,</span><span class="pln"> act</span><span class="pun">=</span><span class="typ">ReluActivation</span><span class="pun">(),</span><span class="pln"> layer_attr</span><span class="pun">=</span><span class="typ">ExtraAttr</span><span class="pun">(</span><span class="pln">drop_rate</span><span class="pun">=</span><span class="lit">0.5</span><span class="pun">))</span></code></li><li class="L4"><code class="language-python"><span class="pln">    fc2 </span><span class="pun">=</span><span class="pln"> fc_layer</span><span class="pun">(</span><span class="pln">input</span><span class="pun">=</span><span class="pln">bn</span><span class="pun">,</span><span class="pln"> size</span><span class="pun">=</span><span class="lit">512</span><span class="pun">,</span><span class="pln"> act</span><span class="pun">=</span><span class="typ">LinearActivation</span><span class="pun">())</span></code></li><li class="L5"><code class="language-python"><span class="pln">    </span><span class="kwd">return</span><span class="pln"> fc2</span></code></li></ol></pre>

<p>2.1. 首先定义了一组卷积网络，即conv_block。卷积核大小为3x3，池化窗口大小为2x2，窗口滑动大小为2，groups决定每组VGG模块是几次连续的卷积操作，dropouts指定Dropout操作的概率。所使用的<code>img_conv_group</code>是在<code>paddle.trainer_config_helpers</code>中预定义的模块，由若干组 <code>Conv-&gt;BN-&gt;ReLu-&gt;Dropout</code> 和 一组 <code>Pooling</code> 组成，</p>

<p>2.2. 五组卷积操作，即 5个conv_block。 第一、二组采用两次连续的卷积操作。第三、四、五组采用三次连续的卷积操作。每组最后一个卷积后面Dropout概率为0，即不使用Dropout操作。</p>

<p>2.3. 最后接两层512维的全连接。</p></li>
<li><p>定义分类器</p>

<p>通过上面VGG网络提取高层特征，然后经过全连接层映射到类别维度大小的向量，再通过Softmax归一化得到每个类别的概率，也可称作分类器。</p>

<pre class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">out </span><span class="pun">=</span><span class="pln"> fc_layer</span><span class="pun">(</span><span class="pln">input</span><span class="pun">=</span><span class="pln">net</span><span class="pun">,</span><span class="pln"> size</span><span class="pun">=</span><span class="pln">class_num</span><span class="pun">,</span><span class="pln"> act</span><span class="pun">=</span><span class="typ">SoftmaxActivation</span><span class="pun">())</span></code></li></ol></pre></li>
<li><p>定义损失函数和网络输出</p>

<p>在有监督训练中需要输入图像对应的类别信息，同样通过<code>data_layer</code>来定义。训练中采用多类交叉熵作为损失函数，并作为网络的输出，预测阶段定义网络的输出为分类器得到的概率信息。</p>

<pre class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">if</span><span class="pln"> </span><span class="kwd">not</span><span class="pln"> is_predict</span><span class="pun">:</span></code></li><li class="L1"><code class="language-python"><span class="pln">    lbl </span><span class="pun">=</span><span class="pln"> data_layer</span><span class="pun">(</span><span class="pln">name</span><span class="pun">=</span><span class="str">"label"</span><span class="pun">,</span><span class="pln"> size</span><span class="pun">=</span><span class="pln">class_num</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">    cost </span><span class="pun">=</span><span class="pln"> classification_cost</span><span class="pun">(</span><span class="pln">input</span><span class="pun">=</span><span class="pln">out</span><span class="pun">,</span><span class="pln"> label</span><span class="pun">=</span><span class="pln">lbl</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"><span class="pln">    outputs</span><span class="pun">(</span><span class="pln">cost</span><span class="pun">)</span></code></li><li class="L4"><code class="language-python"><span class="kwd">else</span><span class="pun">:</span></code></li><li class="L5"><code class="language-python"><span class="pln">    outputs</span><span class="pun">(</span><span class="pln">out</span><span class="pun">)</span></code></li></ol></pre></li>
</ol><div class="md-section-divider"></div><h3 data-anchor-id="svv5" id="resnet-1">ResNet</h3><p data-anchor-id="g96g">ResNet模型的第1、3、4步和VGG模型相同，这里不再介绍。主要介绍第2步即CIFAR10数据集上ResNet核心模块。</p><pre data-anchor-id="2ywh"><code>net = resnet_cifar10(data, depth=56)
</code></pre><p data-anchor-id="zw4f">先介绍<code>resnet_cifar10</code>中的一些基本函数，再介绍网络连接过程。</p><ul data-anchor-id="4wcj">
<li><code>conv_bn_layer</code> : 带BN的卷积层。</li>
<li><code>shortcut</code> : 残差模块的"直连"路径，"直连"实际分两种形式：残差模块输入和输出特征通道数不等时，采用1x1卷积的升维操作；残差模块输入和输出通道相等时，采用直连操作。</li>
<li><code>basicblock</code> : 一个基础残差模块，即图9左边所示，由两组3x3卷积组成的路径和一条"直连"路径组成。</li>
<li><code>bottleneck</code> : 一个瓶颈残差模块，即图9右边所示，由上下1x1卷积和中间3x3卷积组成的路径和一条"直连"路径组成。</li>
<li><p><code>layer_warp</code> : 一组残差模块，由若干个残差模块堆积而成。每组中第一个残差模块滑动窗口大小与其他可以不同，以用来减少特征图在垂直和水平方向的大小。</p>

<pre class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">def</span><span class="pln"> conv_bn_layer</span><span class="pun">(</span><span class="pln">input</span><span class="pun">,</span></code></li><li class="L1"><code class="language-python"><span class="pln">                 ch_out</span><span class="pun">,</span></code></li><li class="L2"><code class="language-python"><span class="pln">                 filter_size</span><span class="pun">,</span></code></li><li class="L3"><code class="language-python"><span class="pln">                 stride</span><span class="pun">,</span></code></li><li class="L4"><code class="language-python"><span class="pln">                 padding</span><span class="pun">,</span></code></li><li class="L5"><code class="language-python"><span class="pln">                 active_type</span><span class="pun">=</span><span class="typ">ReluActivation</span><span class="pun">(),</span></code></li><li class="L6"><code class="language-python"><span class="pln">                 ch_in</span><span class="pun">=</span><span class="kwd">None</span><span class="pun">):</span></code></li><li class="L7"><code class="language-python"><span class="pln">   tmp </span><span class="pun">=</span><span class="pln"> img_conv_layer</span><span class="pun">(</span></code></li><li class="L8"><code class="language-python"><span class="pln">       input</span><span class="pun">=</span><span class="pln">input</span><span class="pun">,</span></code></li><li class="L9"><code class="language-python"><span class="pln">       filter_size</span><span class="pun">=</span><span class="pln">filter_size</span><span class="pun">,</span></code></li><li class="L0"><code class="language-python"><span class="pln">       num_channels</span><span class="pun">=</span><span class="pln">ch_in</span><span class="pun">,</span></code></li><li class="L1"><code class="language-python"><span class="pln">       num_filters</span><span class="pun">=</span><span class="pln">ch_out</span><span class="pun">,</span></code></li><li class="L2"><code class="language-python"><span class="pln">       stride</span><span class="pun">=</span><span class="pln">stride</span><span class="pun">,</span></code></li><li class="L3"><code class="language-python"><span class="pln">       padding</span><span class="pun">=</span><span class="pln">padding</span><span class="pun">,</span></code></li><li class="L4"><code class="language-python"><span class="pln">       act</span><span class="pun">=</span><span class="typ">LinearActivation</span><span class="pun">(),</span></code></li><li class="L5"><code class="language-python"><span class="pln">       bias_attr</span><span class="pun">=</span><span class="kwd">False</span><span class="pun">)</span></code></li><li class="L6"><code class="language-python"><span class="pln">   </span><span class="kwd">return</span><span class="pln"> batch_norm_layer</span><span class="pun">(</span><span class="pln">input</span><span class="pun">=</span><span class="pln">tmp</span><span class="pun">,</span><span class="pln"> act</span><span class="pun">=</span><span class="pln">active_type</span><span class="pun">)</span></code></li><li class="L7"><code class="language-python"></code></li><li class="L8"><code class="language-python"><span class="kwd">def</span><span class="pln"> shortcut</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> n_in</span><span class="pun">,</span><span class="pln"> n_out</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">):</span></code></li><li class="L9"><code class="language-python"><span class="pln">   </span><span class="kwd">if</span><span class="pln"> n_in </span><span class="pun">!=</span><span class="pln"> n_out</span><span class="pun">:</span></code></li><li class="L0"><code class="language-python"><span class="pln">       </span><span class="kwd">return</span><span class="pln"> conv_bn_layer</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> n_out</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">,</span><span class="pln"> </span><span class="typ">LinearActivation</span><span class="pun">())</span></code></li><li class="L1"><code class="language-python"><span class="pln">   </span><span class="kwd">else</span><span class="pun">:</span></code></li><li class="L2"><code class="language-python"><span class="pln">       </span><span class="kwd">return</span><span class="pln"> ipt</span></code></li><li class="L3"><code class="language-python"></code></li><li class="L4"><code class="language-python"><span class="kwd">def</span><span class="pln"> basicblock</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> ch_out</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">):</span></code></li><li class="L5"><code class="language-python"><span class="pln">   ch_in </span><span class="pun">=</span><span class="pln"> ipt</span><span class="pun">.</span><span class="pln">num_filters</span></code></li><li class="L6"><code class="language-python"><span class="pln">   tmp </span><span class="pun">=</span><span class="pln"> conv_bn_layer</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> ch_out</span><span class="pun">,</span><span class="pln"> </span><span class="lit">3</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L7"><code class="language-python"><span class="pln">   tmp </span><span class="pun">=</span><span class="pln"> conv_bn_layer</span><span class="pun">(</span><span class="pln">tmp</span><span class="pun">,</span><span class="pln"> ch_out</span><span class="pun">,</span><span class="pln"> </span><span class="lit">3</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="typ">LinearActivation</span><span class="pun">())</span></code></li><li class="L8"><code class="language-python"><span class="pln">   short </span><span class="pun">=</span><span class="pln"> shortcut</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> ch_in</span><span class="pun">,</span><span class="pln"> ch_out</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">)</span></code></li><li class="L9"><code class="language-python"><span class="pln">   </span><span class="kwd">return</span><span class="pln"> addto_layer</span><span class="pun">(</span><span class="pln">input</span><span class="pun">=[</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> short</span><span class="pun">],</span><span class="pln"> act</span><span class="pun">=</span><span class="typ">ReluActivation</span><span class="pun">())</span></code></li><li class="L0"><code class="language-python"></code></li><li class="L1"><code class="language-python"><span class="kwd">def</span><span class="pln"> bottleneck</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> ch_out</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">):</span></code></li><li class="L2"><code class="language-python"><span class="pln">   ch_in </span><span class="pun">=</span><span class="pln"> ipt</span><span class="pun">.</span><span class="pln">num_filter</span></code></li><li class="L3"><code class="language-python"><span class="pln">   tmp </span><span class="pun">=</span><span class="pln"> conv_bn_layer</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> ch_out</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">)</span></code></li><li class="L4"><code class="language-python"><span class="pln">   tmp </span><span class="pun">=</span><span class="pln"> conv_bn_layer</span><span class="pun">(</span><span class="pln">tmp</span><span class="pun">,</span><span class="pln"> ch_out</span><span class="pun">,</span><span class="pln"> </span><span class="lit">3</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L5"><code class="language-python"><span class="pln">   tmp </span><span class="pun">=</span><span class="pln"> conv_bn_layer</span><span class="pun">(</span><span class="pln">tmp</span><span class="pun">,</span><span class="pln"> ch_out </span><span class="pun">*</span><span class="pln"> </span><span class="lit">4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">,</span><span class="pln"> </span><span class="typ">LinearActivation</span><span class="pun">())</span></code></li><li class="L6"><code class="language-python"><span class="pln">   short </span><span class="pun">=</span><span class="pln"> shortcut</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> ch_in</span><span class="pun">,</span><span class="pln"> ch_out</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">)</span></code></li><li class="L7"><code class="language-python"><span class="pln">   </span><span class="kwd">return</span><span class="pln"> addto_layer</span><span class="pun">(</span><span class="pln">input</span><span class="pun">=[</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> short</span><span class="pun">],</span><span class="pln"> act</span><span class="pun">=</span><span class="typ">ReluActivation</span><span class="pun">())</span></code></li><li class="L8"><code class="language-python"></code></li><li class="L9"><code class="language-python"><span class="kwd">def</span><span class="pln"> layer_warp</span><span class="pun">(</span><span class="pln">block_func</span><span class="pun">,</span><span class="pln"> ipt</span><span class="pun">,</span><span class="pln"> features</span><span class="pun">,</span><span class="pln"> count</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">):</span></code></li><li class="L0"><code class="language-python"><span class="pln">   tmp </span><span class="pun">=</span><span class="pln"> block_func</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> features</span><span class="pun">,</span><span class="pln"> stride</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">   </span><span class="kwd">for</span><span class="pln"> i </span><span class="kwd">in</span><span class="pln"> range</span><span class="pun">(</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> count</span><span class="pun">):</span></code></li><li class="L2"><code class="language-python"><span class="pln">       tmp </span><span class="pun">=</span><span class="pln"> block_func</span><span class="pun">(</span><span class="pln">tmp</span><span class="pun">,</span><span class="pln"> features</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"><span class="pln">   </span><span class="kwd">return</span><span class="pln"> tmp</span></code></li></ol></pre></li>
</ul><p data-anchor-id="piog"><code>resnet_cifar10</code> 的连接结构主要有以下几个过程。</p><ol data-anchor-id="s0uh">
<li>底层输入连接一层 <code>conv_bn_layer</code>，即带BN的卷积层。 </li>
<li>然后连接3组残差模块即下面配置3组 <code>layer_warp</code> ，每组采用图 10 左边残差模块组成。</li>
<li><p>最后对网络做均值池化并返回该层。 </p>

<pre class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">def</span><span class="pln"> resnet_cifar10</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span><span class="pln"> depth</span><span class="pun">=</span><span class="lit">56</span><span class="pun">):</span></code></li><li class="L1"><code class="language-python"><span class="pln">  </span><span class="com"># depth should be one of 20, 32, 44, 56, 110, 1202</span></code></li><li class="L2"><code class="language-python"><span class="pln">  </span><span class="kwd">assert</span><span class="pln"> </span><span class="pun">(</span><span class="pln">depth </span><span class="pun">-</span><span class="pln"> </span><span class="lit">2</span><span class="pun">)</span><span class="pln"> </span><span class="pun">%</span><span class="pln"> </span><span class="lit">6</span><span class="pln"> </span><span class="pun">==</span><span class="pln"> </span><span class="lit">0</span></code></li><li class="L3"><code class="language-python"><span class="pln">  n </span><span class="pun">=</span><span class="pln"> </span><span class="pun">(</span><span class="pln">depth </span><span class="pun">-</span><span class="pln"> </span><span class="lit">2</span><span class="pun">)</span><span class="pln"> </span><span class="pun">/</span><span class="pln"> </span><span class="lit">6</span></code></li><li class="L4"><code class="language-python"><span class="pln">  nStages </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{</span><span class="lit">16</span><span class="pun">,</span><span class="pln"> </span><span class="lit">64</span><span class="pun">,</span><span class="pln"> </span><span class="lit">128</span><span class="pun">}</span></code></li><li class="L5"><code class="language-python"><span class="pln">  conv1 </span><span class="pun">=</span><span class="pln"> conv_bn_layer</span><span class="pun">(</span><span class="pln">ipt</span><span class="pun">,</span></code></li><li class="L6"><code class="language-python"><span class="pln">      ch_in</span><span class="pun">=</span><span class="lit">3</span><span class="pun">,</span></code></li><li class="L7"><code class="language-python"><span class="pln">      ch_out</span><span class="pun">=</span><span class="lit">16</span><span class="pun">,</span></code></li><li class="L8"><code class="language-python"><span class="pln">      filter_size</span><span class="pun">=</span><span class="lit">3</span><span class="pun">,</span></code></li><li class="L9"><code class="language-python"><span class="pln">      stride</span><span class="pun">=</span><span class="lit">1</span><span class="pun">,</span></code></li><li class="L0"><code class="language-python"><span class="pln">      padding</span><span class="pun">=</span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">  res1 </span><span class="pun">=</span><span class="pln"> layer_warp</span><span class="pun">(</span><span class="pln">basicblock</span><span class="pun">,</span><span class="pln"> conv1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">16</span><span class="pun">,</span><span class="pln"> n</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">  res2 </span><span class="pun">=</span><span class="pln"> layer_warp</span><span class="pun">(</span><span class="pln">basicblock</span><span class="pun">,</span><span class="pln"> res1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">32</span><span class="pun">,</span><span class="pln"> n</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"><span class="pln">  res3 </span><span class="pun">=</span><span class="pln"> layer_warp</span><span class="pun">(</span><span class="pln">basicblock</span><span class="pun">,</span><span class="pln"> res2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">64</span><span class="pun">,</span><span class="pln"> n</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">)</span></code></li><li class="L4"><code class="language-python"><span class="pln">  pool </span><span class="pun">=</span><span class="pln"> img_pool_layer</span><span class="pun">(</span><span class="pln">input</span><span class="pun">=</span><span class="pln">res3</span><span class="pun">,</span></code></li><li class="L5"><code class="language-python"><span class="pln">                       pool_size</span><span class="pun">=</span><span class="lit">8</span><span class="pun">,</span></code></li><li class="L6"><code class="language-python"><span class="pln">                       stride</span><span class="pun">=</span><span class="lit">1</span><span class="pun">,</span></code></li><li class="L7"><code class="language-python"><span class="pln">                       pool_type</span><span class="pun">=</span><span class="typ">AvgPooling</span><span class="pun">())</span></code></li><li class="L8"><code class="language-python"><span class="pln">  </span><span class="kwd">return</span><span class="pln"> pool</span></code></li></ol></pre></li>
</ol><p data-anchor-id="ah15">注意：除过第一层卷积层和最后一层全连接层之外，要求三组 <code>layer_warp</code> 总的含参层数能够被6整除，即 <code>resnet_cifar10</code> 的 depth 要满足 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-10-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -771.0516853480245 4933.944444444444 1042.103370696049" style="width: 11.467ex; height: 2.432ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-28"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-64" x="389" y="0"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-65" x="913" y="0"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-70" x="1379" y="0"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-74" x="1883" y="0"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMATHI-68" x="2244" y="0"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-2212" x="3043" y="0"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-32" x="4043" y="0"></use><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#MJMAIN-29" x="4544" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-10">(depth - 2) % 6 == 0</script> 。</p><div class="md-section-divider"></div><h2 data-anchor-id="na01" id="模型训练">模型训练</h2><p data-anchor-id="okly">执行脚本 train.sh 进行模型训练， 其中指定配置文件、设备类型、线程个数、总共训练的轮数、模型存储路径等。</p><pre data-anchor-id="ef8j"><code>sh train.sh
</code></pre><p data-anchor-id="6k9d">脚本 <code>train.sh</code> 如下：</p><pre data-anchor-id="4002"><code>#cfg=models/resnet.py
cfg=models/vgg.py
output=output
log=train.log

paddle train \
    --config=$cfg \
        --use_gpu=true \
        --trainer_count=1 \
        --log_period=100 \
        --num_passes=300 \
        --save_dir=$output \
    2&gt;&amp;1 | tee $log
</code></pre><ul data-anchor-id="2m07">
<li><code>--config=$cfg</code> : 指定配置文件，默认是 <code>models/vgg.py</code>。</li>
<li><code>--use_gpu=true</code> : 指定使用GPU训练，若使用CPU，设置为false。</li>
<li><code>--trainer_count=1</code> : 指定线程个数或GPU个数。</li>
<li><code>--log_period=100</code> : 指定日志打印的batch间隔。</li>
<li><code>--save_dir=$output</code> : 指定模型存储路径。</li>
</ul><p data-anchor-id="28l0">一轮训练log示例如下所示，经过1个pass， 训练集上平均error为0.79958 ，测试集上平均error为0.7858 。</p><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="d5ea"><ol class="linenums"><li class="L0"><code class="language-text"><span class="typ">TrainerInternal</span><span class="pun">.</span><span class="pln">cpp</span><span class="pun">:</span><span class="lit">165</span><span class="pun">]</span><span class="pln">  </span><span class="typ">Batch</span><span class="pun">=</span><span class="lit">300</span><span class="pln"> samples</span><span class="pun">=</span><span class="lit">38400</span><span class="pln"> </span><span class="typ">AvgCost</span><span class="pun">=</span><span class="lit">2.07708</span><span class="pln"> </span><span class="typ">CurrentCost</span><span class="pun">=</span><span class="lit">1.96158</span><span class="pln"> </span><span class="typ">Eval</span><span class="pun">:</span><span class="pln"> classification_error_evaluator</span><span class="pun">=</span><span class="lit">0.81151</span><span class="pln">  </span><span class="typ">CurrentEval</span><span class="pun">:</span><span class="pln"> classification_error_evaluator</span><span class="pun">=</span><span class="lit">0.789297</span></code></li><li class="L1"><code class="language-text"><span class="typ">TrainerInternal</span><span class="pun">.</span><span class="pln">cpp</span><span class="pun">:</span><span class="lit">181</span><span class="pun">]</span><span class="pln">  </span><span class="typ">Pass</span><span class="pun">=</span><span class="lit">0</span><span class="pln"> </span><span class="typ">Batch</span><span class="pun">=</span><span class="lit">391</span><span class="pln"> samples</span><span class="pun">=</span><span class="lit">50000</span><span class="pln"> </span><span class="typ">AvgCost</span><span class="pun">=</span><span class="lit">2.03348</span><span class="pln"> </span><span class="typ">Eval</span><span class="pun">:</span><span class="pln"> classification_error_evaluator</span><span class="pun">=</span><span class="lit">0.79958</span></code></li><li class="L2"><code class="language-text"><span class="typ">Tester</span><span class="pun">.</span><span class="pln">cpp</span><span class="pun">:</span><span class="lit">115</span><span class="pun">]</span><span class="pln">  </span><span class="typ">Test</span><span class="pln"> samples</span><span class="pun">=</span><span class="lit">10000</span><span class="pln"> cost</span><span class="pun">=</span><span class="lit">1.99246</span><span class="pln"> </span><span class="typ">Eval</span><span class="pun">:</span><span class="pln"> classification_error_evaluator</span><span class="pun">=</span><span class="lit">0.7858</span></code></li></ol></pre><p align="center" data-anchor-id="07wk">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/plot.png" width="400"><br>
图12. CIFAR10数据集上VGG模型的分类错误率
</p><div class="md-section-divider"></div><h2 data-anchor-id="1axb" id="模型应用">模型应用</h2><p data-anchor-id="a4xg">在训练完成后，模型会保存在路径 <code>output/pass-%05d</code> 下，例如第300个pass的模型会保存在路径 <code>output/pass-00299</code>。 可以使用脚本 <code>classify.py</code> 对图片进行预测或提取特征，注意该脚本默认使用模型配置为 <code>models/vgg.py</code>，</p><div class="md-section-divider"></div><h3 data-anchor-id="edho" id="预测">预测</h3><p data-anchor-id="qhar">可以按照下面方式预测图片的类别，默认使用GPU预测，如果使用CPU预测，在后面加参数 <code>-c</code>即可。</p><pre data-anchor-id="am9x"><code>python classify.py --job=predict --model=output/pass-00299 --data=image/dog.png # -c
</code></pre><p data-anchor-id="ihir">预测结果为：</p><pre data-anchor-id="131e"><code>Label of image/dog.png is: 5
</code></pre><div class="md-section-divider"></div><h3 data-anchor-id="zize" id="特征提取">特征提取</h3><p data-anchor-id="jtvl">可以按照下面方式对图片提取特征，和预测使用方式不同的是指定job类型为extract，并需要指定提取的层。<code>classify.py</code> 默认以第一层卷积特征为例提取特征，并画出了类似图13的可视化图。VGG模型的第一层卷积有64个通道，图13展示了每个通道的灰度图。</p><pre data-anchor-id="9eh3"><code>python classify.py --job=extract --model=output/pass-00299 --data=image/dog.png # -c
</code></pre><p align="center" data-anchor-id="ob85">
<img src="https://raw.githubusercontent.com/PaddlePaddle/book/develop/image_classification/image/fea_conv0.png" width="500"><br>
图13. 卷积特征可视化图 
</p><div class="md-section-divider"></div><h2 data-anchor-id="iawn" id="总结">总结</h2><p data-anchor-id="vz6e">传统图像分类方法由多个阶段构成，框架较为复杂，而端到端的CNN模型结构可一步到位，而且大幅度提升了分类准确率。本文我们首先介绍VGG、GoogleNet、ResNet三个经典的模型；然后基于CIFAR10数据集，介绍如何使用PaddlePaddle配置和训练CNN模型，尤其是VGG和ResNet模型；最后介绍如何使用PaddlePaddle的API接口对图片进行预测和特征提取。对于其他数据集比如ImageNet，配置和训练流程是同样的，大家可以自行进行实验。</p><div class="md-section-divider"></div><h2 data-anchor-id="5u0o" id="参考文献">参考文献</h2><p data-anchor-id="l46l">[1] D. G. Lowe, <a href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf" target="_blank">Distinctive image features from scale-invariant keypoints</a>. IJCV, 60(2):91-110, 2004.</p><p data-anchor-id="9lzt">[2] N. Dalal, B. Triggs, <a href="http://vision.stanford.edu/teaching/cs231b_spring1213/papers/CVPR05_DalalTriggs.pdf" target="_blank">Histograms of Oriented Gradients for Human Detection</a>, Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2005.</p><p data-anchor-id="mdjp">[3] Ahonen, T., Hadid, A., and Pietikinen, M. (2006). <a href="http://ieeexplore.ieee.org/document/1717463/" target="_blank">Face description with local binary patterns: Application to face recognition</a>. PAMI, 28. </p><p data-anchor-id="841z">[4] J. Sivic, A. Zisserman, <a href="http://www.robots.ox.ac.uk/~vgg/publications/papers/sivic03.pdf" target="_blank">Video Google: A Text Retrieval Approach to Object Matching in Videos</a>, Proc. Ninth Int'l Conf. Computer Vision, pp. 1470-1478, 2003.</p><p data-anchor-id="y1r0">[5] B. Olshausen, D. Field, <a href="http://redwood.psych.cornell.edu/papers/olshausen_field_1997.pdf" target="_blank">Sparse Coding with an Overcomplete Basis Set: A Strategy Employed by V1?</a>, Vision Research, vol. 37, pp. 3311-3325, 1997.</p><p data-anchor-id="vlkn">[6] Wang, J., Yang, J., Yu, K., Lv, F., Huang, T., and Gong, Y. (2010). <a href="http://ieeexplore.ieee.org/abstract/document/5540018/" target="_blank">Locality-constrained Linear Coding for image classification</a>. In CVPR.</p><p data-anchor-id="tow3">[7] Perronnin, F., Sánchez, J., &amp; Mensink, T. (2010). <a href="http://dl.acm.org/citation.cfm?id=1888101" target="_blank">Improving the fisher kernel for large-scale image classification</a>. In ECCV (4).</p><p data-anchor-id="mflg">[8] Lin, Y., Lv, F., Cao, L., Zhu, S., Yang, M., Cour, T., Yu, K., and Huang, T. (2011). <a href="http://ieeexplore.ieee.org/document/5995477/" target="_blank">Large-scale image clas- sification: Fast feature extraction and SVM training</a>. In CVPR.</p><p data-anchor-id="cim7">[9] Krizhevsky, A., Sutskever, I., and Hinton, G. (2012). <a href="http://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf" target="_blank">ImageNet classification with deep convolutional neu- ral networks</a>. In NIPS.</p><p data-anchor-id="z1pg">[10] G.E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R.R. Salakhutdinov. <a href="https://arxiv.org/abs/1207.0580" target="_blank">Improving neural networks by preventing co-adaptation of feature detectors</a>. arXiv preprint arXiv:1207.0580, 2012.</p><p data-anchor-id="hef7">[11] K. Chatfield, K. Simonyan, A. Vedaldi, A. Zisserman. <a href="https://arxiv.org/abs/1405.3531" target="_blank">Return of the Devil in the Details: Delving Deep into Convolutional Nets</a>. BMVC, 2014。</p><p data-anchor-id="1mm1">[12] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A., <a href="https://arxiv.org/abs/1409.4842" target="_blank">Going deeper with convolutions</a>. In: CVPR. (2015)</p><p data-anchor-id="g962">[13] Lin, M., Chen, Q., and Yan, S. <a href="https://arxiv.org/abs/1312.4400" target="_blank">Network in network</a>. In Proc. ICLR, 2014.</p><p data-anchor-id="xzx2">[14] S. Ioffe and C. Szegedy. <a href="https://arxiv.org/abs/1502.03167" target="_blank">Batch normalization: Accelerating deep network training by reducing internal covariate shift</a>. In ICML, 2015.</p><p data-anchor-id="w8xg">[15] K. He, X. Zhang, S. Ren, J. Sun. <a href="https://arxiv.org/abs/1512.03385" target="_blank">Deep Residual Learning for Image Recognition</a>. CVPR 2016.</p><p data-anchor-id="gwoo">[16] Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z. <a href="https://arxiv.org/abs/1512.00567" target="_blank">Rethinking the incep-tion architecture for computer vision</a>. In: CVPR. (2016).</p><p data-anchor-id="21y3">[17] Szegedy, C., Ioffe, S., Vanhoucke, V. <a href="https://arxiv.org/abs/1602.07261" target="_blank">Inception-v4, inception-resnet and the impact of residual connections on learning</a>. arXiv:1602.07261 (2016).</p><p data-anchor-id="qr78">[18] Everingham, M., Eslami, S. M. A., Van Gool, L., Williams, C. K. I., Winn, J. and Zisserman, A. The Pascal Visual Object Classes Challenge: A Retrospective. International Journal of Computer Vision, 111(1), 98-136, 2015.</p><p data-anchor-id="4wev">[19] He, K., Zhang, X., Ren, S., and Sun, J. <a href="https://arxiv.org/abs/1502.01852" target="_blank">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a>. ArXiv e-prints, February 2015.</p><p data-anchor-id="sm90">[20] <a href="http://deeplearning.net/tutorial/lenet.html" target="_blank">http://deeplearning.net/tutorial/lenet.html</a></p><p data-anchor-id="vhmp">[21] <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">https://www.cs.toronto.edu/~kriz/cifar.html</a></p><p data-anchor-id="d6jv">[22] <a href="http://cs231n.github.io/classification/" target="_blank">http://cs231n.github.io/classification/</a></p><p data-anchor-id="scwx"><br> <br>
<img src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" alt="知识共享许可协议"></p><p data-anchor-id="nxbu">本教程由<a href="http://book.paddlepaddle.org" target="_blank">PaddlePaddle</a>创作，采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">知识共享 署名-非商业性使用-相同方式共享 4.0 国际 许可协议</a>进行许可。</p></div>
</body>
</html>
